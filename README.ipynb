{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure Python and Jupyter are set up locally first (and if necessary relaunch VSCode). There is a `shell.nix` that does this for you if you have Nix installed, or you can use a virtual env created from the global Python.\n",
    "\n",
    "```bash\n",
    "$ python3 -m venv .venv\n",
    "$ . .venv/bin/activate\n",
    "$ pip install jupyter ipykernel notebook\n",
    "$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some LLM code copied from [Qwak.com](https://www.qwak.com/post/utilizing-llms-with-embedding-stores)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8f7fa63b644267bd7dbdc2e26600c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load only the training split of the dataset\n",
    "train_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split='train')\n",
    "\n",
    "# Filter the dataset to only include entries with the 'closed_qa' category\n",
    "closed_qa_dataset = train_dataset.filter(lambda example: example['category'] == 'closed_qa')\n",
    "\n",
    "print(closed_qa_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class VectorStore:\n",
    "\n",
    "    def __init__(self, collection_name):\n",
    "       # Initialize the embedding model\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "        self.chroma_client = chromadb.Client()\n",
    "        self.collection = self.chroma_client.create_collection(name=collection_name)\n",
    "\n",
    "    # Method to populate the vector store with embeddings from a dataset\n",
    "    def populate_vectors(self, dataset):\n",
    "        for i, item in enumerate(dataset):\n",
    "            combined_text = f\"{item['instruction']}. {item['context']}\"\n",
    "            embeddings = self.embedding_model.encode(combined_text).tolist()\n",
    "            self.collection.add(embeddings=[embeddings], documents=[item['context']], ids=[f\"id_{i}\"])\n",
    "\n",
    "    # Method to search the ChromaDB collection for relevant context based on a query\n",
    "    def search_context(self, query, n_results=1):\n",
    "        query_embeddings = self.embedding_model.encode(query).tolist()\n",
    "        return self.collection.query(query_embeddings=query_embeddings, n_results=n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection knowledge-base already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mknowledge-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mVectorStore.__init__\u001b[0;34m(self, collection_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/multi-qa-MiniLM-L6-cos-v1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/scratch/enhance-llm/.venv/lib/python3.12/site-packages/chromadb/api/client.py:117\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[0;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[1;32m    126\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[1;32m    127\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    128\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[1;32m    129\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[1;32m    130\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/scratch/enhance-llm/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/dev/scratch/enhance-llm/.venv/lib/python3.12/site-packages/chromadb/api/segment.py:176\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    164\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    166\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# TODO: wrap sysdb call in try except and log error if it fails\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n",
      "File \u001b[0;32m~/dev/scratch/enhance-llm/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/dev/scratch/enhance-llm/.venv/lib/python3.12/site-packages/chromadb/db/mixins/sysdb.py:229\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[0;34m(self, id, name, configuration, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[1;32m    224\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[1;32m    225\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    227\u001b[0m         )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    233\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection knowledge-base already exists"
     ]
    }
   ],
   "source": [
    "vector_store = VectorStore(\"knowledge-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.populate_vectors(closed_qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 1773\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(id=UUID('75f8f444-ae1a-45b4-8df2-8e78457308a9'), name='knowledge-base', configuration_json={'hnsw_configuration': {'space': 'l2', 'ef_construction': 100, 'ef_search': 10, 'num_threads': 20, 'M': 16, 'resize_factor': 1.2, 'batch_size': 100, 'sync_threshold': 1000, '_type': 'HNSWConfigurationInternal'}, '_type': 'CollectionConfigurationInternal'}, metadata=None, dimension=None, tenant='default_tenant', database='default_database', version=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.collection.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Komorida was born in Kumamoto Prefecture on July 10, 1981. After graduating from high school, he joined the J1 League club Avispa Fukuoka in 2000. Although he debuted as a midfielder in 2001, he did not play much and the club was relegated to the J2 League at the end of the 2001 season. In 2002, he moved to the J2 club Oita Trinita. He became a regular player as a defensive midfielder and the club won the championship in 2002 and was promoted in 2003. He played many matches until 2005. In September 2005, he moved to the J2 club Montedio Yamagata. In 2006, he moved to the J2 club Vissel Kobe. Although he became a regular player as a defensive midfielder, his gradually was played less during the summer. In 2007, he moved to the Japan Football League club Rosso Kumamoto (later Roasso Kumamoto) based in his local region. He played as a regular player and the club was promoted to J2 in 2008. Although he did not play as much, he still played in many matches. In 2010, he moved to Indonesia and joined Persela Lamongan. In July 2010, he returned to Japan and joined the J2 club Giravanz Kitakyushu. He played often as a defensive midfielder and center back until 2012 when he retired.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"When was Tomoaki Komorida born?\"\n",
    "vector_store.search_context(user_question)['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_response = vector_store.search_context(user_question)\n",
    "context = \"\".join(context_response['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19039bf6fbfc4f31a7f34b538b1d7421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d0a5667bd641f28ca25b9536699618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:  58%|#####7    | 2.59G/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd557bec4883485ca18094d6fedb8f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af90d78dcf304496ac4636b453b3cde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98215ad3093412db31609f2a354aee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc47ab9f152438fada0d813f6e88ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1731d829424788a91fb2a5b99d53f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\", offload_folder=\"offload\",)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\", offload_folder=\"offload\",)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "\t\"text-generation\",\n",
    "\tmodel=model,\n",
    "\ttokenizer=tokenizer,\n",
    "\ttorch_dtype=torch.bfloat16,\n",
    "\ttrust_remote_code=True,\n",
    "\tdevice_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"{context}\\n\\n{user_question}\"\n",
    "text = pipeline(\n",
    "            prompt,\n",
    "            max_length=500,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tomoaki Komorida birthday is on July 10, 1981.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]['generated_text'].split(user_question)[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting docopt==0.6.2 (from pipreqs)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ipython==8.12.3 (from pipreqs)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nbconvert<8.0.0,>=7.11.0 in ./.venv/lib/python3.12/site-packages (from pipreqs) (7.16.4)\n",
      "Collecting yarg==0.1.9 (from pipreqs)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting backcall (from ipython==8.12.3->pipreqs)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (0.1.7)\n",
      "Collecting pickleshare (from ipython==8.12.3->pipreqs)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython==8.12.3->pipreqs) (4.9.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from yarg==0.1.9->pipreqs) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.10.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (24.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in ./.venv/lib/python3.12/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython==8.12.3->pipreqs) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.2.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.12/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (8.6.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./.venv/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.23.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython==8.12.3->pipreqs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->pipreqs) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->yarg==0.1.9->pipreqs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->yarg==0.1.9->pipreqs) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->yarg==0.1.9->pipreqs) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->yarg==0.1.9->pipreqs) (2024.7.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack-data->ipython==8.12.3->pipreqs) (0.2.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.4.1)\n",
      "Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=0d029a8ff4638c40fa356fa0811eb9062726c077827fea0c117d5162219a1c1b\n",
      "  Stored in directory: /home/dsyer/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: pickleshare, docopt, backcall, yarg, ipython, pipreqs\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.26.0\n",
      "    Uninstalling ipython-8.26.0:\n",
      "      Successfully uninstalled ipython-8.26.0\n",
      "Successfully installed backcall-0.2.0 docopt-0.6.2 ipython-8.12.3 pickleshare-0.7.5 pipreqs-0.5.0 yarg-0.1.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pipreqs\n",
    "jupyter nbconvert --to=python README.ipynb\n",
    "pipreqs ==ignore \".venv\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to make a cup of tea?</td>\n",
       "      <td></td>\n",
       "      <td>Boil water. Add tea bag. Pour water into cup. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td></td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td></td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the capital of Italy?</td>\n",
       "      <td></td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the capital of Spain?</td>\n",
       "      <td></td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the capital of Portugal?</td>\n",
       "      <td></td>\n",
       "      <td>Lisbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the capital of Greece?</td>\n",
       "      <td></td>\n",
       "      <td>Athens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the capital of Turkey?</td>\n",
       "      <td></td>\n",
       "      <td>Ankara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the capital of Egypt?</td>\n",
       "      <td></td>\n",
       "      <td>Cairo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the capital of South Africa?</td>\n",
       "      <td></td>\n",
       "      <td>Pretoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the capital of Nigeria?</td>\n",
       "      <td></td>\n",
       "      <td>Abuja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the capital of Kenya?</td>\n",
       "      <td></td>\n",
       "      <td>Nairobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the capital of India?</td>\n",
       "      <td></td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the capital of China?</td>\n",
       "      <td></td>\n",
       "      <td>Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the capital of Japan?</td>\n",
       "      <td></td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the capital of Australia?</td>\n",
       "      <td></td>\n",
       "      <td>Canberra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is the capital of New Zealand?</td>\n",
       "      <td></td>\n",
       "      <td>Wellington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What is the capital of Canada?</td>\n",
       "      <td></td>\n",
       "      <td>Ottawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is the capital of the United States?</td>\n",
       "      <td></td>\n",
       "      <td>Washington D.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the capital of Brazil?</td>\n",
       "      <td></td>\n",
       "      <td>Brasilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the capital of Argentina?</td>\n",
       "      <td></td>\n",
       "      <td>Buenos Aires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the capital of Chile?</td>\n",
       "      <td></td>\n",
       "      <td>Santiago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the capital of Peru?</td>\n",
       "      <td></td>\n",
       "      <td>Lima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  instruction context  \\\n",
       "0                   How to make a cup of tea?           \n",
       "1              What is the capital of France?           \n",
       "2             What is the capital of Germany?           \n",
       "3               What is the capital of Italy?           \n",
       "4               What is the capital of Spain?           \n",
       "5            What is the capital of Portugal?           \n",
       "6              What is the capital of Greece?           \n",
       "7              What is the capital of Turkey?           \n",
       "8               What is the capital of Egypt?           \n",
       "9        What is the capital of South Africa?           \n",
       "10            What is the capital of Nigeria?           \n",
       "11              What is the capital of Kenya?           \n",
       "12              What is the capital of India?           \n",
       "13              What is the capital of China?           \n",
       "14              What is the capital of Japan?           \n",
       "15          What is the capital of Australia?           \n",
       "16        What is the capital of New Zealand?           \n",
       "17             What is the capital of Canada?           \n",
       "18  What is the capital of the United States?           \n",
       "19             What is the capital of Brazil?           \n",
       "20          What is the capital of Argentina?           \n",
       "21              What is the capital of Chile?           \n",
       "22               What is the capital of Peru?           \n",
       "\n",
       "                                             response  \n",
       "0   Boil water. Add tea bag. Pour water into cup. ...  \n",
       "1                                               Paris  \n",
       "2                                              Berlin  \n",
       "3                                                Rome  \n",
       "4                                              Madrid  \n",
       "5                                              Lisbon  \n",
       "6                                              Athens  \n",
       "7                                              Ankara  \n",
       "8                                               Cairo  \n",
       "9                                            Pretoria  \n",
       "10                                              Abuja  \n",
       "11                                            Nairobi  \n",
       "12                                          New Delhi  \n",
       "13                                            Beijing  \n",
       "14                                              Tokyo  \n",
       "15                                           Canberra  \n",
       "16                                         Wellington  \n",
       "17                                             Ottawa  \n",
       "18                                    Washington D.C.  \n",
       "19                                           Brasilia  \n",
       "20                                       Buenos Aires  \n",
       "21                                           Santiago  \n",
       "22                                               Lima  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_json(\"data/lines.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"./data\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__class__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
